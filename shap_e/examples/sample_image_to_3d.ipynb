{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964ccced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget\n",
    "from shap_e.util.image_util import load_image\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eed3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d922637",
   "metadata": {},
   "outputs": [],
   "source": [
    "xm = load_model('transmitter', device=device)\n",
    "model = load_model('image300M', device=device)\n",
    "diffusion = diffusion_from_config(load_config('diffusion'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d329d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602429e93edb42edaea7100df1d6516a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# default values:4\n",
    "batch_size = 1\n",
    "# default values:3.0\n",
    "guidance_scale = 3.0\n",
    "\n",
    "# To get the best result, you should remove the background and show only the object of interest to the model.\n",
    "# image = load_image(\"example_data/dra_1.png\")\n",
    "image_name = \"sh9\"\n",
    "\n",
    "# Define your maximum allowed size\n",
    "max_width = 800\n",
    "max_height = 600\n",
    "\n",
    "image = load_image(f\"img/{image_name}.png\")\n",
    "# Check if the image is larger than the maximum dimensions\n",
    "if image.width > max_width or image.height > max_height:\n",
    "    # Resize the image, maintaining the aspect ratio\n",
    "    image.thumbnail((max_width, max_height))\n",
    "\n",
    "latents = sample_latents(\n",
    "    batch_size=batch_size,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale,\n",
    "    model_kwargs=dict(images=[image] * batch_size),\n",
    "    progress=True,\n",
    "    clip_denoised=True,\n",
    "    use_fp16=True,\n",
    "    use_karras=True,\n",
    "    karras_steps=64,\n",
    "    sigma_min=1e-3,\n",
    "    sigma_max=160,\n",
    "    s_churn=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a0f27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating cameras...\n",
      "creating images...1left\n",
      "images done, saving...1left\n",
      "saving...\n",
      "0 saved\n",
      "1 saved\n",
      "2 saved\n",
      "3 saved\n",
      "4 saved\n",
      "5 saved\n",
      "6 saved\n",
      "7 saved\n",
      "8 saved\n",
      "9 saved\n",
      "10 saved\n",
      "11 saved\n",
      "12 saved\n",
      "13 saved\n",
      "14 saved\n",
      "15 saved\n",
      "16 saved\n",
      "17 saved\n",
      "18 saved\n",
      "19 saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f516bef4c8040e6865eab79df9d9dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<img src=\"data:image/gif;base64,R0lGODlhgACAAIcAAMHDwrW2t6mqqqCgqpSXpoySi4WGmnuEfX5+knZ8i3R3inBzhmâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render_mode = 'nerf' # you can change this to 'stf' / 'nerf' (Neural Radiance Fields)\n",
    "size = 128 # this is the size of the renders; higher values take longer to render.\n",
    "\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "save_dir = 'output_gif'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print('creating cameras...')\n",
    "cameras = create_pan_cameras(size, device)\n",
    "\n",
    "\n",
    "for i, latent in enumerate(latents):\n",
    "    print(f'creating images...{len(latents)-i}left')\n",
    "\n",
    "    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    print(f'images done, saving...{len(latents)-i}left')\n",
    "    print('saving...')\n",
    "    # save\n",
    "    pil_images = []\n",
    "    for j, img in enumerate(images):\n",
    "        if isinstance(img, Image.Image):\n",
    "            # If img is already a PIL Image, no need to convert\n",
    "            pil_img = img\n",
    "        elif hasattr(img, 'cpu') and callable(getattr(img, 'cpu')):\n",
    "            # If it has a 'cpu' attribute, it might be a PyTorch tensor\n",
    "            pil_img = Image.fromarray(img.cpu().detach().numpy().astype('uint8'))\n",
    "        elif isinstance(img, np.ndarray):\n",
    "            # If it's a NumPy array, convert directly to PIL\n",
    "            pil_img = Image.fromarray(img)\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported image type: {type(img)}\")\n",
    "\n",
    "        # Save the image\n",
    "        pil_images.append(pil_img)\n",
    "        print(f'{j} saved')\n",
    "    \n",
    "    gif_path = os.path.join(save_dir, f\"{image_name}_{i}.gif\")\n",
    "    pil_images[0].save(\n",
    "        gif_path,\n",
    "        save_all=True,\n",
    "        append_images=pil_images[1:],\n",
    "        duration=100,  # Duration between frames in milliseconds (adjust as needed)\n",
    "        loop=0  # Number of times the GIF should loop (0 means infinite)\n",
    "    )\n",
    "\n",
    "    display(gif_widget(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "633da2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_mode = 'nerf' # you can change this to 'stf' for mesh rendering\n",
    "# size = 64 # this is the size of the renders; higher values take longer to render.\n",
    "\n",
    "# cameras = create_pan_cameras(size, device)\n",
    "# for i, latent in enumerate(latents):\n",
    "#     images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "#     display(gif_widget(images))\n",
    "\n",
    "\n",
    "# Example of saving the latents as meshes.\n",
    "##############################################\n",
    "\n",
    "# from shap_e.util.notebooks import decode_latent_mesh\n",
    "\n",
    "# file_name = \"mesh_dra_1\"\n",
    "\n",
    "# for i, latent in enumerate(latents):\n",
    "#     t = decode_latent_mesh(xm, latent).tri_mesh()\n",
    "#     with open(f'{file_name}_{i}.ply', 'wb') as f:\n",
    "#         t.write_ply(f)\n",
    "#     with open(f'{file_name}_{i}.obj', 'w') as f:\n",
    "#         t.write_obj(f)\n",
    "\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76f84b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### loop folder########\n",
    "# batch_size = 1\n",
    "# guidance_scale = 3.0\n",
    "\n",
    "# max_width = 800\n",
    "# max_height = 600\n",
    "\n",
    "# source_dir = 'img'\n",
    "# save_dir = 'output_gif'\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# # Loop through all files in the source directory\n",
    "# for image_name in os.listdir(source_dir):\n",
    "#     if image_name.endswith(('.png', '.jpg', '.jpeg')):  # Check if the file is an image\n",
    "#         image_path = os.path.join(source_dir, image_name)\n",
    "#         print(f\"Processing {image_path}...\")\n",
    "        \n",
    "#         image = load_image(image_path)\n",
    "#         if image.width > max_width or image.height > max_height:\n",
    "#             image.thumbnail((max_width, max_height))\n",
    "        \n",
    "#         latents = sample_latents(\n",
    "#             batch_size=batch_size,\n",
    "#             model=model,\n",
    "#             diffusion=diffusion,\n",
    "#             guidance_scale=guidance_scale,\n",
    "#             model_kwargs=dict(images=[image] * batch_size),\n",
    "#             progress=True,\n",
    "#             clip_denoised=True,\n",
    "#             use_fp16=True,\n",
    "#             use_karras=True,\n",
    "#             karras_steps=64,\n",
    "#             sigma_min=1e-3,\n",
    "#             sigma_max=160,\n",
    "#             s_churn=0,\n",
    "#         )\n",
    "\n",
    "#         render_mode = 'nerf'\n",
    "#         size = 128\n",
    "#         cameras = create_pan_cameras(size, device)\n",
    "\n",
    "#         pil_images = []\n",
    "#         for i, latent in enumerate(latents):\n",
    "#             images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "#             for img in images:\n",
    "#                 if isinstance(img, Image.Image):\n",
    "#                     pil_img = img\n",
    "#                 elif hasattr(img, 'cpu') and callable(getattr(img, 'cpu')):\n",
    "#                     pil_img = Image.fromarray(img.cpu().detach().numpy().astype('uint8'))\n",
    "#                 elif isinstance(img, np.ndarray):\n",
    "#                     pil_img = Image.fromarray(img)\n",
    "#                 else:\n",
    "#                     continue  # Skip if the image type is not supported\n",
    "#                 pil_images.append(pil_img)\n",
    "\n",
    "#         gif_filename = os.path.splitext(image_name)[0] + \".gif\"\n",
    "#         gif_path = os.path.join(save_dir, gif_filename)\n",
    "#         pil_images[0].save(\n",
    "#             gif_path,\n",
    "#             save_all=True,\n",
    "#             append_images=pil_images[1:],\n",
    "#             duration=100,\n",
    "#             loop=0\n",
    "#         )\n",
    "#         print(f\"Generated {gif_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
